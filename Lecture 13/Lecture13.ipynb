{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능 검증 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   0  \n",
       "1  0.0052  0.0044   0  \n",
       "2  0.0095  0.0078   0  \n",
       "3  0.0040  0.0117   0  \n",
       "4  0.0107  0.0094   0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# 광물 데이터 \n",
    "df = pd.read_csv(\"./sonar3.csv\", header=None)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60\n",
       "1    111\n",
       "0     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()\n",
    "\n",
    "# 일반 암석 : 97, 광석 : 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:60]\n",
    "y = df.iloc[:, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 딥러닝 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras import Sequential, Input \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(60,)))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 - 0s - loss: 0.6758 - accuracy: 0.6250 - 225ms/epoch - 11ms/step\n",
      "Epoch 2/200\n",
      "21/21 - 0s - loss: 0.6496 - accuracy: 0.6635 - 14ms/epoch - 689us/step\n",
      "Epoch 3/200\n",
      "21/21 - 0s - loss: 0.6327 - accuracy: 0.7500 - 14ms/epoch - 679us/step\n",
      "Epoch 4/200\n",
      "21/21 - 0s - loss: 0.6162 - accuracy: 0.7692 - 15ms/epoch - 707us/step\n",
      "Epoch 5/200\n",
      "21/21 - 0s - loss: 0.6025 - accuracy: 0.7404 - 14ms/epoch - 687us/step\n",
      "Epoch 6/200\n",
      "21/21 - 0s - loss: 0.5846 - accuracy: 0.7885 - 13ms/epoch - 637us/step\n",
      "Epoch 7/200\n",
      "21/21 - 0s - loss: 0.5693 - accuracy: 0.7837 - 13ms/epoch - 636us/step\n",
      "Epoch 8/200\n",
      "21/21 - 0s - loss: 0.5508 - accuracy: 0.7837 - 13ms/epoch - 625us/step\n",
      "Epoch 9/200\n",
      "21/21 - 0s - loss: 0.5325 - accuracy: 0.8077 - 13ms/epoch - 628us/step\n",
      "Epoch 10/200\n",
      "21/21 - 0s - loss: 0.5211 - accuracy: 0.7692 - 13ms/epoch - 619us/step\n",
      "Epoch 11/200\n",
      "21/21 - 0s - loss: 0.5074 - accuracy: 0.7692 - 13ms/epoch - 634us/step\n",
      "Epoch 12/200\n",
      "21/21 - 0s - loss: 0.4882 - accuracy: 0.8029 - 14ms/epoch - 647us/step\n",
      "Epoch 13/200\n",
      "21/21 - 0s - loss: 0.4749 - accuracy: 0.8125 - 13ms/epoch - 633us/step\n",
      "Epoch 14/200\n",
      "21/21 - 0s - loss: 0.4616 - accuracy: 0.8221 - 13ms/epoch - 631us/step\n",
      "Epoch 15/200\n",
      "21/21 - 0s - loss: 0.4482 - accuracy: 0.7981 - 38ms/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "21/21 - 0s - loss: 0.4427 - accuracy: 0.8029 - 17ms/epoch - 818us/step\n",
      "Epoch 17/200\n",
      "21/21 - 0s - loss: 0.4242 - accuracy: 0.8413 - 14ms/epoch - 681us/step\n",
      "Epoch 18/200\n",
      "21/21 - 0s - loss: 0.4222 - accuracy: 0.8125 - 14ms/epoch - 666us/step\n",
      "Epoch 19/200\n",
      "21/21 - 0s - loss: 0.4060 - accuracy: 0.8269 - 14ms/epoch - 650us/step\n",
      "Epoch 20/200\n",
      "21/21 - 0s - loss: 0.4076 - accuracy: 0.8365 - 13ms/epoch - 632us/step\n",
      "Epoch 21/200\n",
      "21/21 - 0s - loss: 0.4014 - accuracy: 0.8221 - 14ms/epoch - 644us/step\n",
      "Epoch 22/200\n",
      "21/21 - 0s - loss: 0.3947 - accuracy: 0.8365 - 14ms/epoch - 645us/step\n",
      "Epoch 23/200\n",
      "21/21 - 0s - loss: 0.3763 - accuracy: 0.8510 - 14ms/epoch - 650us/step\n",
      "Epoch 24/200\n",
      "21/21 - 0s - loss: 0.3808 - accuracy: 0.8317 - 13ms/epoch - 634us/step\n",
      "Epoch 25/200\n",
      "21/21 - 0s - loss: 0.3856 - accuracy: 0.8125 - 13ms/epoch - 639us/step\n",
      "Epoch 26/200\n",
      "21/21 - 0s - loss: 0.3684 - accuracy: 0.8510 - 14ms/epoch - 678us/step\n",
      "Epoch 27/200\n",
      "21/21 - 0s - loss: 0.3616 - accuracy: 0.8413 - 16ms/epoch - 751us/step\n",
      "Epoch 28/200\n",
      "21/21 - 0s - loss: 0.3595 - accuracy: 0.8702 - 14ms/epoch - 648us/step\n",
      "Epoch 29/200\n",
      "21/21 - 0s - loss: 0.3471 - accuracy: 0.8462 - 14ms/epoch - 643us/step\n",
      "Epoch 30/200\n",
      "21/21 - 0s - loss: 0.3443 - accuracy: 0.8798 - 14ms/epoch - 643us/step\n",
      "Epoch 31/200\n",
      "21/21 - 0s - loss: 0.3330 - accuracy: 0.8654 - 13ms/epoch - 626us/step\n",
      "Epoch 32/200\n",
      "21/21 - 0s - loss: 0.3340 - accuracy: 0.8606 - 13ms/epoch - 619us/step\n",
      "Epoch 33/200\n",
      "21/21 - 0s - loss: 0.3277 - accuracy: 0.8750 - 13ms/epoch - 631us/step\n",
      "Epoch 34/200\n",
      "21/21 - 0s - loss: 0.3148 - accuracy: 0.8846 - 13ms/epoch - 636us/step\n",
      "Epoch 35/200\n",
      "21/21 - 0s - loss: 0.3262 - accuracy: 0.8654 - 13ms/epoch - 643us/step\n",
      "Epoch 36/200\n",
      "21/21 - 0s - loss: 0.3096 - accuracy: 0.8942 - 13ms/epoch - 626us/step\n",
      "Epoch 37/200\n",
      "21/21 - 0s - loss: 0.3077 - accuracy: 0.8798 - 13ms/epoch - 622us/step\n",
      "Epoch 38/200\n",
      "21/21 - 0s - loss: 0.3091 - accuracy: 0.8894 - 13ms/epoch - 624us/step\n",
      "Epoch 39/200\n",
      "21/21 - 0s - loss: 0.3123 - accuracy: 0.8702 - 13ms/epoch - 625us/step\n",
      "Epoch 40/200\n",
      "21/21 - 0s - loss: 0.3075 - accuracy: 0.8702 - 14ms/epoch - 649us/step\n",
      "Epoch 41/200\n",
      "21/21 - 0s - loss: 0.2931 - accuracy: 0.8894 - 13ms/epoch - 628us/step\n",
      "Epoch 42/200\n",
      "21/21 - 0s - loss: 0.2963 - accuracy: 0.8894 - 13ms/epoch - 631us/step\n",
      "Epoch 43/200\n",
      "21/21 - 0s - loss: 0.2844 - accuracy: 0.8846 - 13ms/epoch - 634us/step\n",
      "Epoch 44/200\n",
      "21/21 - 0s - loss: 0.2787 - accuracy: 0.9087 - 13ms/epoch - 641us/step\n",
      "Epoch 45/200\n",
      "21/21 - 0s - loss: 0.2744 - accuracy: 0.9135 - 13ms/epoch - 625us/step\n",
      "Epoch 46/200\n",
      "21/21 - 0s - loss: 0.2689 - accuracy: 0.9087 - 13ms/epoch - 639us/step\n",
      "Epoch 47/200\n",
      "21/21 - 0s - loss: 0.2713 - accuracy: 0.8990 - 14ms/epoch - 650us/step\n",
      "Epoch 48/200\n",
      "21/21 - 0s - loss: 0.2620 - accuracy: 0.9087 - 13ms/epoch - 635us/step\n",
      "Epoch 49/200\n",
      "21/21 - 0s - loss: 0.2775 - accuracy: 0.8942 - 13ms/epoch - 631us/step\n",
      "Epoch 50/200\n",
      "21/21 - 0s - loss: 0.2535 - accuracy: 0.9038 - 13ms/epoch - 637us/step\n",
      "Epoch 51/200\n",
      "21/21 - 0s - loss: 0.2574 - accuracy: 0.8990 - 14ms/epoch - 651us/step\n",
      "Epoch 52/200\n",
      "21/21 - 0s - loss: 0.2578 - accuracy: 0.9135 - 14ms/epoch - 649us/step\n",
      "Epoch 53/200\n",
      "21/21 - 0s - loss: 0.2479 - accuracy: 0.9135 - 13ms/epoch - 638us/step\n",
      "Epoch 54/200\n",
      "21/21 - 0s - loss: 0.2422 - accuracy: 0.9183 - 13ms/epoch - 642us/step\n",
      "Epoch 55/200\n",
      "21/21 - 0s - loss: 0.2405 - accuracy: 0.9231 - 14ms/epoch - 657us/step\n",
      "Epoch 56/200\n",
      "21/21 - 0s - loss: 0.2361 - accuracy: 0.9327 - 14ms/epoch - 660us/step\n",
      "Epoch 57/200\n",
      "21/21 - 0s - loss: 0.2384 - accuracy: 0.9183 - 14ms/epoch - 648us/step\n",
      "Epoch 58/200\n",
      "21/21 - 0s - loss: 0.2315 - accuracy: 0.9231 - 14ms/epoch - 643us/step\n",
      "Epoch 59/200\n",
      "21/21 - 0s - loss: 0.2258 - accuracy: 0.9327 - 14ms/epoch - 653us/step\n",
      "Epoch 60/200\n",
      "21/21 - 0s - loss: 0.2225 - accuracy: 0.9423 - 14ms/epoch - 663us/step\n",
      "Epoch 61/200\n",
      "21/21 - 0s - loss: 0.2223 - accuracy: 0.9183 - 14ms/epoch - 645us/step\n",
      "Epoch 62/200\n",
      "21/21 - 0s - loss: 0.2155 - accuracy: 0.9327 - 14ms/epoch - 647us/step\n",
      "Epoch 63/200\n",
      "21/21 - 0s - loss: 0.2116 - accuracy: 0.9423 - 13ms/epoch - 635us/step\n",
      "Epoch 64/200\n",
      "21/21 - 0s - loss: 0.2114 - accuracy: 0.9327 - 13ms/epoch - 639us/step\n",
      "Epoch 65/200\n",
      "21/21 - 0s - loss: 0.2030 - accuracy: 0.9519 - 13ms/epoch - 636us/step\n",
      "Epoch 66/200\n",
      "21/21 - 0s - loss: 0.2019 - accuracy: 0.9471 - 13ms/epoch - 633us/step\n",
      "Epoch 67/200\n",
      "21/21 - 0s - loss: 0.1963 - accuracy: 0.9519 - 13ms/epoch - 637us/step\n",
      "Epoch 68/200\n",
      "21/21 - 0s - loss: 0.1970 - accuracy: 0.9471 - 13ms/epoch - 637us/step\n",
      "Epoch 69/200\n",
      "21/21 - 0s - loss: 0.1913 - accuracy: 0.9423 - 13ms/epoch - 634us/step\n",
      "Epoch 70/200\n",
      "21/21 - 0s - loss: 0.1882 - accuracy: 0.9567 - 13ms/epoch - 634us/step\n",
      "Epoch 71/200\n",
      "21/21 - 0s - loss: 0.1878 - accuracy: 0.9615 - 13ms/epoch - 626us/step\n",
      "Epoch 72/200\n",
      "21/21 - 0s - loss: 0.1862 - accuracy: 0.9471 - 13ms/epoch - 620us/step\n",
      "Epoch 73/200\n",
      "21/21 - 0s - loss: 0.1831 - accuracy: 0.9519 - 13ms/epoch - 625us/step\n",
      "Epoch 74/200\n",
      "21/21 - 0s - loss: 0.1836 - accuracy: 0.9471 - 13ms/epoch - 622us/step\n",
      "Epoch 75/200\n",
      "21/21 - 0s - loss: 0.1703 - accuracy: 0.9615 - 13ms/epoch - 632us/step\n",
      "Epoch 76/200\n",
      "21/21 - 0s - loss: 0.1807 - accuracy: 0.9423 - 13ms/epoch - 631us/step\n",
      "Epoch 77/200\n",
      "21/21 - 0s - loss: 0.1713 - accuracy: 0.9663 - 13ms/epoch - 640us/step\n",
      "Epoch 78/200\n",
      "21/21 - 0s - loss: 0.1638 - accuracy: 0.9615 - 13ms/epoch - 631us/step\n",
      "Epoch 79/200\n",
      "21/21 - 0s - loss: 0.1619 - accuracy: 0.9615 - 13ms/epoch - 631us/step\n",
      "Epoch 80/200\n",
      "21/21 - 0s - loss: 0.1641 - accuracy: 0.9615 - 13ms/epoch - 636us/step\n",
      "Epoch 81/200\n",
      "21/21 - 0s - loss: 0.1659 - accuracy: 0.9471 - 13ms/epoch - 630us/step\n",
      "Epoch 82/200\n",
      "21/21 - 0s - loss: 0.1545 - accuracy: 0.9615 - 13ms/epoch - 625us/step\n",
      "Epoch 83/200\n",
      "21/21 - 0s - loss: 0.1538 - accuracy: 0.9615 - 13ms/epoch - 635us/step\n",
      "Epoch 84/200\n",
      "21/21 - 0s - loss: 0.1493 - accuracy: 0.9712 - 13ms/epoch - 636us/step\n",
      "Epoch 85/200\n",
      "21/21 - 0s - loss: 0.1507 - accuracy: 0.9615 - 13ms/epoch - 625us/step\n",
      "Epoch 86/200\n",
      "21/21 - 0s - loss: 0.1431 - accuracy: 0.9567 - 13ms/epoch - 627us/step\n",
      "Epoch 87/200\n",
      "21/21 - 0s - loss: 0.1449 - accuracy: 0.9615 - 13ms/epoch - 620us/step\n",
      "Epoch 88/200\n",
      "21/21 - 0s - loss: 0.1403 - accuracy: 0.9663 - 13ms/epoch - 634us/step\n",
      "Epoch 89/200\n",
      "21/21 - 0s - loss: 0.1312 - accuracy: 0.9712 - 13ms/epoch - 629us/step\n",
      "Epoch 90/200\n",
      "21/21 - 0s - loss: 0.1274 - accuracy: 0.9712 - 13ms/epoch - 628us/step\n",
      "Epoch 91/200\n",
      "21/21 - 0s - loss: 0.1258 - accuracy: 0.9712 - 13ms/epoch - 637us/step\n",
      "Epoch 92/200\n",
      "21/21 - 0s - loss: 0.1241 - accuracy: 0.9663 - 14ms/epoch - 643us/step\n",
      "Epoch 93/200\n",
      "21/21 - 0s - loss: 0.1215 - accuracy: 0.9663 - 13ms/epoch - 633us/step\n",
      "Epoch 94/200\n",
      "21/21 - 0s - loss: 0.1175 - accuracy: 0.9712 - 13ms/epoch - 626us/step\n",
      "Epoch 95/200\n",
      "21/21 - 0s - loss: 0.1170 - accuracy: 0.9712 - 13ms/epoch - 636us/step\n",
      "Epoch 96/200\n",
      "21/21 - 0s - loss: 0.1233 - accuracy: 0.9663 - 13ms/epoch - 635us/step\n",
      "Epoch 97/200\n",
      "21/21 - 0s - loss: 0.1099 - accuracy: 0.9760 - 13ms/epoch - 636us/step\n",
      "Epoch 98/200\n",
      "21/21 - 0s - loss: 0.1093 - accuracy: 0.9760 - 13ms/epoch - 634us/step\n",
      "Epoch 99/200\n",
      "21/21 - 0s - loss: 0.1096 - accuracy: 0.9712 - 13ms/epoch - 638us/step\n",
      "Epoch 100/200\n",
      "21/21 - 0s - loss: 0.1130 - accuracy: 0.9712 - 13ms/epoch - 633us/step\n",
      "Epoch 101/200\n",
      "21/21 - 0s - loss: 0.1034 - accuracy: 0.9808 - 13ms/epoch - 635us/step\n",
      "Epoch 102/200\n",
      "21/21 - 0s - loss: 0.1050 - accuracy: 0.9712 - 13ms/epoch - 638us/step\n",
      "Epoch 103/200\n",
      "21/21 - 0s - loss: 0.0980 - accuracy: 0.9760 - 13ms/epoch - 629us/step\n",
      "Epoch 104/200\n",
      "21/21 - 0s - loss: 0.0939 - accuracy: 0.9808 - 13ms/epoch - 629us/step\n",
      "Epoch 105/200\n",
      "21/21 - 0s - loss: 0.0895 - accuracy: 0.9904 - 13ms/epoch - 640us/step\n",
      "Epoch 106/200\n",
      "21/21 - 0s - loss: 0.1031 - accuracy: 0.9808 - 13ms/epoch - 629us/step\n",
      "Epoch 107/200\n",
      "21/21 - 0s - loss: 0.1011 - accuracy: 0.9760 - 13ms/epoch - 637us/step\n",
      "Epoch 108/200\n",
      "21/21 - 0s - loss: 0.0943 - accuracy: 0.9712 - 13ms/epoch - 631us/step\n",
      "Epoch 109/200\n",
      "21/21 - 0s - loss: 0.0803 - accuracy: 0.9904 - 13ms/epoch - 631us/step\n",
      "Epoch 110/200\n",
      "21/21 - 0s - loss: 0.0818 - accuracy: 0.9808 - 13ms/epoch - 638us/step\n",
      "Epoch 111/200\n",
      "21/21 - 0s - loss: 0.0803 - accuracy: 0.9904 - 13ms/epoch - 636us/step\n",
      "Epoch 112/200\n",
      "21/21 - 0s - loss: 0.0905 - accuracy: 0.9760 - 13ms/epoch - 637us/step\n",
      "Epoch 113/200\n",
      "21/21 - 0s - loss: 0.0727 - accuracy: 0.9904 - 13ms/epoch - 631us/step\n",
      "Epoch 114/200\n",
      "21/21 - 0s - loss: 0.0821 - accuracy: 0.9904 - 13ms/epoch - 634us/step\n",
      "Epoch 115/200\n",
      "21/21 - 0s - loss: 0.0815 - accuracy: 0.9856 - 13ms/epoch - 638us/step\n",
      "Epoch 116/200\n",
      "21/21 - 0s - loss: 0.0745 - accuracy: 0.9904 - 13ms/epoch - 639us/step\n",
      "Epoch 117/200\n",
      "21/21 - 0s - loss: 0.0778 - accuracy: 0.9904 - 13ms/epoch - 627us/step\n",
      "Epoch 118/200\n",
      "21/21 - 0s - loss: 0.0658 - accuracy: 0.9904 - 13ms/epoch - 635us/step\n",
      "Epoch 119/200\n",
      "21/21 - 0s - loss: 0.0635 - accuracy: 0.9904 - 13ms/epoch - 632us/step\n",
      "Epoch 120/200\n",
      "21/21 - 0s - loss: 0.0629 - accuracy: 0.9904 - 13ms/epoch - 633us/step\n",
      "Epoch 121/200\n",
      "21/21 - 0s - loss: 0.0680 - accuracy: 0.9904 - 13ms/epoch - 639us/step\n",
      "Epoch 122/200\n",
      "21/21 - 0s - loss: 0.0602 - accuracy: 0.9952 - 13ms/epoch - 634us/step\n",
      "Epoch 123/200\n",
      "21/21 - 0s - loss: 0.0609 - accuracy: 0.9904 - 13ms/epoch - 631us/step\n",
      "Epoch 124/200\n",
      "21/21 - 0s - loss: 0.0619 - accuracy: 0.9952 - 13ms/epoch - 641us/step\n",
      "Epoch 125/200\n",
      "21/21 - 0s - loss: 0.0538 - accuracy: 0.9952 - 13ms/epoch - 624us/step\n",
      "Epoch 126/200\n",
      "21/21 - 0s - loss: 0.0531 - accuracy: 0.9952 - 13ms/epoch - 620us/step\n",
      "Epoch 127/200\n",
      "21/21 - 0s - loss: 0.0549 - accuracy: 0.9952 - 13ms/epoch - 642us/step\n",
      "Epoch 128/200\n",
      "21/21 - 0s - loss: 0.0501 - accuracy: 0.9904 - 13ms/epoch - 633us/step\n",
      "Epoch 129/200\n",
      "21/21 - 0s - loss: 0.0493 - accuracy: 1.0000 - 13ms/epoch - 633us/step\n",
      "Epoch 130/200\n",
      "21/21 - 0s - loss: 0.0502 - accuracy: 0.9952 - 13ms/epoch - 631us/step\n",
      "Epoch 131/200\n",
      "21/21 - 0s - loss: 0.0480 - accuracy: 1.0000 - 13ms/epoch - 633us/step\n",
      "Epoch 132/200\n",
      "21/21 - 0s - loss: 0.0490 - accuracy: 0.9952 - 13ms/epoch - 625us/step\n",
      "Epoch 133/200\n",
      "21/21 - 0s - loss: 0.0493 - accuracy: 1.0000 - 13ms/epoch - 624us/step\n",
      "Epoch 134/200\n",
      "21/21 - 0s - loss: 0.0425 - accuracy: 1.0000 - 13ms/epoch - 635us/step\n",
      "Epoch 135/200\n",
      "21/21 - 0s - loss: 0.0418 - accuracy: 1.0000 - 13ms/epoch - 634us/step\n",
      "Epoch 136/200\n",
      "21/21 - 0s - loss: 0.0420 - accuracy: 1.0000 - 13ms/epoch - 632us/step\n",
      "Epoch 137/200\n",
      "21/21 - 0s - loss: 0.0403 - accuracy: 1.0000 - 13ms/epoch - 630us/step\n",
      "Epoch 138/200\n",
      "21/21 - 0s - loss: 0.0423 - accuracy: 1.0000 - 13ms/epoch - 628us/step\n",
      "Epoch 139/200\n",
      "21/21 - 0s - loss: 0.0376 - accuracy: 1.0000 - 13ms/epoch - 627us/step\n",
      "Epoch 140/200\n",
      "21/21 - 0s - loss: 0.0425 - accuracy: 1.0000 - 13ms/epoch - 633us/step\n",
      "Epoch 141/200\n",
      "21/21 - 0s - loss: 0.0401 - accuracy: 1.0000 - 13ms/epoch - 635us/step\n",
      "Epoch 142/200\n",
      "21/21 - 0s - loss: 0.0406 - accuracy: 1.0000 - 13ms/epoch - 635us/step\n",
      "Epoch 143/200\n",
      "21/21 - 0s - loss: 0.0375 - accuracy: 1.0000 - 13ms/epoch - 634us/step\n",
      "Epoch 144/200\n",
      "21/21 - 0s - loss: 0.0327 - accuracy: 1.0000 - 13ms/epoch - 628us/step\n",
      "Epoch 145/200\n",
      "21/21 - 0s - loss: 0.0319 - accuracy: 1.0000 - 13ms/epoch - 626us/step\n",
      "Epoch 146/200\n",
      "21/21 - 0s - loss: 0.0322 - accuracy: 1.0000 - 13ms/epoch - 624us/step\n",
      "Epoch 147/200\n",
      "21/21 - 0s - loss: 0.0339 - accuracy: 1.0000 - 13ms/epoch - 631us/step\n",
      "Epoch 148/200\n",
      "21/21 - 0s - loss: 0.0302 - accuracy: 1.0000 - 14ms/epoch - 648us/step\n",
      "Epoch 149/200\n",
      "21/21 - 0s - loss: 0.0309 - accuracy: 1.0000 - 13ms/epoch - 638us/step\n",
      "Epoch 150/200\n",
      "21/21 - 0s - loss: 0.0302 - accuracy: 1.0000 - 34ms/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "21/21 - 0s - loss: 0.0305 - accuracy: 1.0000 - 14ms/epoch - 654us/step\n",
      "Epoch 152/200\n",
      "21/21 - 0s - loss: 0.0286 - accuracy: 1.0000 - 13ms/epoch - 630us/step\n",
      "Epoch 153/200\n",
      "21/21 - 0s - loss: 0.0273 - accuracy: 1.0000 - 13ms/epoch - 634us/step\n",
      "Epoch 154/200\n",
      "21/21 - 0s - loss: 0.0267 - accuracy: 1.0000 - 13ms/epoch - 625us/step\n",
      "Epoch 155/200\n",
      "21/21 - 0s - loss: 0.0277 - accuracy: 1.0000 - 13ms/epoch - 642us/step\n",
      "Epoch 156/200\n",
      "21/21 - 0s - loss: 0.0244 - accuracy: 1.0000 - 13ms/epoch - 637us/step\n",
      "Epoch 157/200\n",
      "21/21 - 0s - loss: 0.0255 - accuracy: 1.0000 - 13ms/epoch - 631us/step\n",
      "Epoch 158/200\n",
      "21/21 - 0s - loss: 0.0234 - accuracy: 1.0000 - 13ms/epoch - 630us/step\n",
      "Epoch 159/200\n",
      "21/21 - 0s - loss: 0.0222 - accuracy: 1.0000 - 13ms/epoch - 638us/step\n",
      "Epoch 160/200\n",
      "21/21 - 0s - loss: 0.0226 - accuracy: 1.0000 - 13ms/epoch - 638us/step\n",
      "Epoch 161/200\n",
      "21/21 - 0s - loss: 0.0221 - accuracy: 1.0000 - 13ms/epoch - 640us/step\n",
      "Epoch 162/200\n",
      "21/21 - 0s - loss: 0.0212 - accuracy: 1.0000 - 13ms/epoch - 636us/step\n",
      "Epoch 163/200\n",
      "21/21 - 0s - loss: 0.0210 - accuracy: 1.0000 - 13ms/epoch - 629us/step\n",
      "Epoch 164/200\n",
      "21/21 - 0s - loss: 0.0209 - accuracy: 1.0000 - 13ms/epoch - 637us/step\n",
      "Epoch 165/200\n",
      "21/21 - 0s - loss: 0.0218 - accuracy: 1.0000 - 13ms/epoch - 626us/step\n",
      "Epoch 166/200\n",
      "21/21 - 0s - loss: 0.0227 - accuracy: 1.0000 - 13ms/epoch - 629us/step\n",
      "Epoch 167/200\n",
      "21/21 - 0s - loss: 0.0210 - accuracy: 1.0000 - 13ms/epoch - 631us/step\n",
      "Epoch 168/200\n",
      "21/21 - 0s - loss: 0.0212 - accuracy: 1.0000 - 13ms/epoch - 640us/step\n",
      "Epoch 169/200\n",
      "21/21 - 0s - loss: 0.0183 - accuracy: 1.0000 - 13ms/epoch - 631us/step\n",
      "Epoch 170/200\n",
      "21/21 - 0s - loss: 0.0175 - accuracy: 1.0000 - 13ms/epoch - 628us/step\n",
      "Epoch 171/200\n",
      "21/21 - 0s - loss: 0.0179 - accuracy: 1.0000 - 13ms/epoch - 636us/step\n",
      "Epoch 172/200\n",
      "21/21 - 0s - loss: 0.0171 - accuracy: 1.0000 - 13ms/epoch - 636us/step\n",
      "Epoch 173/200\n",
      "21/21 - 0s - loss: 0.0187 - accuracy: 1.0000 - 13ms/epoch - 635us/step\n",
      "Epoch 174/200\n",
      "21/21 - 0s - loss: 0.0181 - accuracy: 1.0000 - 14ms/epoch - 681us/step\n",
      "Epoch 175/200\n",
      "21/21 - 0s - loss: 0.0159 - accuracy: 1.0000 - 13ms/epoch - 634us/step\n",
      "Epoch 176/200\n",
      "21/21 - 0s - loss: 0.0153 - accuracy: 1.0000 - 13ms/epoch - 630us/step\n",
      "Epoch 177/200\n",
      "21/21 - 0s - loss: 0.0151 - accuracy: 1.0000 - 13ms/epoch - 618us/step\n",
      "Epoch 178/200\n",
      "21/21 - 0s - loss: 0.0145 - accuracy: 1.0000 - 13ms/epoch - 638us/step\n",
      "Epoch 179/200\n",
      "21/21 - 0s - loss: 0.0160 - accuracy: 1.0000 - 14ms/epoch - 644us/step\n",
      "Epoch 180/200\n",
      "21/21 - 0s - loss: 0.0151 - accuracy: 1.0000 - 13ms/epoch - 630us/step\n",
      "Epoch 181/200\n",
      "21/21 - 0s - loss: 0.0138 - accuracy: 1.0000 - 13ms/epoch - 639us/step\n",
      "Epoch 182/200\n",
      "21/21 - 0s - loss: 0.0148 - accuracy: 1.0000 - 13ms/epoch - 624us/step\n",
      "Epoch 183/200\n",
      "21/21 - 0s - loss: 0.0145 - accuracy: 1.0000 - 13ms/epoch - 629us/step\n",
      "Epoch 184/200\n",
      "21/21 - 0s - loss: 0.0134 - accuracy: 1.0000 - 13ms/epoch - 632us/step\n",
      "Epoch 185/200\n",
      "21/21 - 0s - loss: 0.0126 - accuracy: 1.0000 - 13ms/epoch - 630us/step\n",
      "Epoch 186/200\n",
      "21/21 - 0s - loss: 0.0129 - accuracy: 1.0000 - 13ms/epoch - 624us/step\n",
      "Epoch 187/200\n",
      "21/21 - 0s - loss: 0.0128 - accuracy: 1.0000 - 13ms/epoch - 628us/step\n",
      "Epoch 188/200\n",
      "21/21 - 0s - loss: 0.0132 - accuracy: 1.0000 - 13ms/epoch - 642us/step\n",
      "Epoch 189/200\n",
      "21/21 - 0s - loss: 0.0115 - accuracy: 1.0000 - 13ms/epoch - 636us/step\n",
      "Epoch 190/200\n",
      "21/21 - 0s - loss: 0.0111 - accuracy: 1.0000 - 13ms/epoch - 638us/step\n",
      "Epoch 191/200\n",
      "21/21 - 0s - loss: 0.0114 - accuracy: 1.0000 - 13ms/epoch - 625us/step\n",
      "Epoch 192/200\n",
      "21/21 - 0s - loss: 0.0112 - accuracy: 1.0000 - 13ms/epoch - 623us/step\n",
      "Epoch 193/200\n",
      "21/21 - 0s - loss: 0.0106 - accuracy: 1.0000 - 13ms/epoch - 639us/step\n",
      "Epoch 194/200\n",
      "21/21 - 0s - loss: 0.0121 - accuracy: 1.0000 - 13ms/epoch - 629us/step\n",
      "Epoch 195/200\n",
      "21/21 - 0s - loss: 0.0110 - accuracy: 1.0000 - 13ms/epoch - 623us/step\n",
      "Epoch 196/200\n",
      "21/21 - 0s - loss: 0.0113 - accuracy: 1.0000 - 13ms/epoch - 638us/step\n",
      "Epoch 197/200\n",
      "21/21 - 0s - loss: 0.0106 - accuracy: 1.0000 - 13ms/epoch - 626us/step\n",
      "Epoch 198/200\n",
      "21/21 - 0s - loss: 0.0096 - accuracy: 1.0000 - 13ms/epoch - 636us/step\n",
      "Epoch 199/200\n",
      "21/21 - 0s - loss: 0.0092 - accuracy: 1.0000 - 13ms/epoch - 626us/step\n",
      "Epoch 200/200\n",
      "21/21 - 0s - loss: 0.0108 - accuracy: 1.0000 - 13ms/epoch - 641us/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y, epochs=200, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정확도가 거의 100%에 가까움 -> 어떤 광물이라도 100% 확률로 판별하는 모델이라고 하기 어려움 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과적합 \n",
    "<b>모델이 학습 데이터셋 안에서 일정 수준 이상의 예측 정확도를 보이지만, 새로운 데이터에 적용하면 맞지 않음 </b>\n",
    "\n",
    "<h4>해결 방법</h4>\n",
    "학습셋, 테스트셋으로 완전히 구분 -> 학습 + 테스트 병행\n",
    "1. 학습셋으로 딥러닝 학습 \n",
    "2. 학습 결과 저장 \n",
    "3. 테스트셋으로 검증 및 예측 수행 \n",
    "\n",
    "##### 은닉층 개수에 따른 학습셋 및 테스트셋에서 예측률 \n",
    "은닉층 개수가 올라감에 따라 학습셋(계속 상승) & 테스트셋(상승하다가 떨어짐)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 사용 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습셋, 테스트셋 분리 \n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "학습용 손실 : 1.23 %\n",
      "학습용 정확도 : 100.00 %\n"
     ]
    }
   ],
   "source": [
    "# 만든 모델을 테스트셋에 적용 : model.evaluate()\n",
    "# model.evaluate() : loss[0], accuracy[1] 계산하여 출력 \n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"학습용 손실 : %.2f %%\" % (score[0]*100))\n",
    "print(\"학습용 정확도 : %.2f %%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 - 0s - loss: 0.7380 - accuracy: 0.4759 - 213ms/epoch - 14ms/step\n",
      "Epoch 2/200\n",
      "15/15 - 0s - loss: 0.6945 - accuracy: 0.4759 - 11ms/epoch - 723us/step\n",
      "Epoch 3/200\n",
      "15/15 - 0s - loss: 0.6817 - accuracy: 0.5517 - 10ms/epoch - 694us/step\n",
      "Epoch 4/200\n",
      "15/15 - 0s - loss: 0.6722 - accuracy: 0.6207 - 10ms/epoch - 693us/step\n",
      "Epoch 5/200\n",
      "15/15 - 0s - loss: 0.6659 - accuracy: 0.6621 - 10ms/epoch - 676us/step\n",
      "Epoch 6/200\n",
      "15/15 - 0s - loss: 0.6473 - accuracy: 0.7103 - 10ms/epoch - 683us/step\n",
      "Epoch 7/200\n",
      "15/15 - 0s - loss: 0.6255 - accuracy: 0.6897 - 10ms/epoch - 671us/step\n",
      "Epoch 8/200\n",
      "15/15 - 0s - loss: 0.6150 - accuracy: 0.6828 - 10ms/epoch - 647us/step\n",
      "Epoch 9/200\n",
      "15/15 - 0s - loss: 0.6005 - accuracy: 0.7310 - 10ms/epoch - 680us/step\n",
      "Epoch 10/200\n",
      "15/15 - 0s - loss: 0.5908 - accuracy: 0.7310 - 10ms/epoch - 660us/step\n",
      "Epoch 11/200\n",
      "15/15 - 0s - loss: 0.5802 - accuracy: 0.7655 - 10ms/epoch - 645us/step\n",
      "Epoch 12/200\n",
      "15/15 - 0s - loss: 0.5704 - accuracy: 0.7517 - 10ms/epoch - 657us/step\n",
      "Epoch 13/200\n",
      "15/15 - 0s - loss: 0.5604 - accuracy: 0.7517 - 10ms/epoch - 654us/step\n",
      "Epoch 14/200\n",
      "15/15 - 0s - loss: 0.5520 - accuracy: 0.7379 - 10ms/epoch - 645us/step\n",
      "Epoch 15/200\n",
      "15/15 - 0s - loss: 0.5432 - accuracy: 0.7448 - 10ms/epoch - 668us/step\n",
      "Epoch 16/200\n",
      "15/15 - 0s - loss: 0.5347 - accuracy: 0.7655 - 10ms/epoch - 656us/step\n",
      "Epoch 17/200\n",
      "15/15 - 0s - loss: 0.5253 - accuracy: 0.7931 - 10ms/epoch - 648us/step\n",
      "Epoch 18/200\n",
      "15/15 - 0s - loss: 0.5176 - accuracy: 0.7517 - 10ms/epoch - 643us/step\n",
      "Epoch 19/200\n",
      "15/15 - 0s - loss: 0.5116 - accuracy: 0.7448 - 10ms/epoch - 646us/step\n",
      "Epoch 20/200\n",
      "15/15 - 0s - loss: 0.5086 - accuracy: 0.7379 - 10ms/epoch - 644us/step\n",
      "Epoch 21/200\n",
      "15/15 - 0s - loss: 0.4949 - accuracy: 0.7793 - 10ms/epoch - 659us/step\n",
      "Epoch 22/200\n",
      "15/15 - 0s - loss: 0.4929 - accuracy: 0.7586 - 10ms/epoch - 648us/step\n",
      "Epoch 23/200\n",
      "15/15 - 0s - loss: 0.4827 - accuracy: 0.7655 - 10ms/epoch - 663us/step\n",
      "Epoch 24/200\n",
      "15/15 - 0s - loss: 0.4749 - accuracy: 0.7862 - 10ms/epoch - 674us/step\n",
      "Epoch 25/200\n",
      "15/15 - 0s - loss: 0.4673 - accuracy: 0.7931 - 10ms/epoch - 649us/step\n",
      "Epoch 26/200\n",
      "15/15 - 0s - loss: 0.4660 - accuracy: 0.7724 - 10ms/epoch - 650us/step\n",
      "Epoch 27/200\n",
      "15/15 - 0s - loss: 0.4546 - accuracy: 0.8000 - 10ms/epoch - 655us/step\n",
      "Epoch 28/200\n",
      "15/15 - 0s - loss: 0.4520 - accuracy: 0.8000 - 10ms/epoch - 665us/step\n",
      "Epoch 29/200\n",
      "15/15 - 0s - loss: 0.4424 - accuracy: 0.8000 - 10ms/epoch - 663us/step\n",
      "Epoch 30/200\n",
      "15/15 - 0s - loss: 0.4404 - accuracy: 0.7793 - 10ms/epoch - 665us/step\n",
      "Epoch 31/200\n",
      "15/15 - 0s - loss: 0.4313 - accuracy: 0.7931 - 10ms/epoch - 652us/step\n",
      "Epoch 32/200\n",
      "15/15 - 0s - loss: 0.4313 - accuracy: 0.7862 - 10ms/epoch - 655us/step\n",
      "Epoch 33/200\n",
      "15/15 - 0s - loss: 0.4165 - accuracy: 0.8345 - 10ms/epoch - 663us/step\n",
      "Epoch 34/200\n",
      "15/15 - 0s - loss: 0.4137 - accuracy: 0.8138 - 10ms/epoch - 654us/step\n",
      "Epoch 35/200\n",
      "15/15 - 0s - loss: 0.4130 - accuracy: 0.8207 - 10ms/epoch - 661us/step\n",
      "Epoch 36/200\n",
      "15/15 - 0s - loss: 0.4186 - accuracy: 0.8000 - 10ms/epoch - 639us/step\n",
      "Epoch 37/200\n",
      "15/15 - 0s - loss: 0.4016 - accuracy: 0.8207 - 10ms/epoch - 655us/step\n",
      "Epoch 38/200\n",
      "15/15 - 0s - loss: 0.4034 - accuracy: 0.8345 - 10ms/epoch - 657us/step\n",
      "Epoch 39/200\n",
      "15/15 - 0s - loss: 0.3926 - accuracy: 0.8276 - 10ms/epoch - 654us/step\n",
      "Epoch 40/200\n",
      "15/15 - 0s - loss: 0.3838 - accuracy: 0.8483 - 10ms/epoch - 658us/step\n",
      "Epoch 41/200\n",
      "15/15 - 0s - loss: 0.3807 - accuracy: 0.8276 - 10ms/epoch - 655us/step\n",
      "Epoch 42/200\n",
      "15/15 - 0s - loss: 0.3774 - accuracy: 0.8483 - 10ms/epoch - 652us/step\n",
      "Epoch 43/200\n",
      "15/15 - 0s - loss: 0.3649 - accuracy: 0.8690 - 10ms/epoch - 670us/step\n",
      "Epoch 44/200\n",
      "15/15 - 0s - loss: 0.3644 - accuracy: 0.8483 - 10ms/epoch - 656us/step\n",
      "Epoch 45/200\n",
      "15/15 - 0s - loss: 0.3694 - accuracy: 0.8483 - 10ms/epoch - 644us/step\n",
      "Epoch 46/200\n",
      "15/15 - 0s - loss: 0.3598 - accuracy: 0.8552 - 10ms/epoch - 658us/step\n",
      "Epoch 47/200\n",
      "15/15 - 0s - loss: 0.3478 - accuracy: 0.8759 - 10ms/epoch - 657us/step\n",
      "Epoch 48/200\n",
      "15/15 - 0s - loss: 0.3434 - accuracy: 0.8828 - 10ms/epoch - 653us/step\n",
      "Epoch 49/200\n",
      "15/15 - 0s - loss: 0.3425 - accuracy: 0.8483 - 10ms/epoch - 662us/step\n",
      "Epoch 50/200\n",
      "15/15 - 0s - loss: 0.3634 - accuracy: 0.8276 - 10ms/epoch - 649us/step\n",
      "Epoch 51/200\n",
      "15/15 - 0s - loss: 0.3405 - accuracy: 0.8552 - 10ms/epoch - 654us/step\n",
      "Epoch 52/200\n",
      "15/15 - 0s - loss: 0.3274 - accuracy: 0.8828 - 10ms/epoch - 663us/step\n",
      "Epoch 53/200\n",
      "15/15 - 0s - loss: 0.3248 - accuracy: 0.8828 - 10ms/epoch - 656us/step\n",
      "Epoch 54/200\n",
      "15/15 - 0s - loss: 0.3219 - accuracy: 0.8828 - 10ms/epoch - 674us/step\n",
      "Epoch 55/200\n",
      "15/15 - 0s - loss: 0.3136 - accuracy: 0.8828 - 10ms/epoch - 658us/step\n",
      "Epoch 56/200\n",
      "15/15 - 0s - loss: 0.3118 - accuracy: 0.8828 - 10ms/epoch - 651us/step\n",
      "Epoch 57/200\n",
      "15/15 - 0s - loss: 0.3135 - accuracy: 0.8966 - 10ms/epoch - 647us/step\n",
      "Epoch 58/200\n",
      "15/15 - 0s - loss: 0.3003 - accuracy: 0.8828 - 10ms/epoch - 639us/step\n",
      "Epoch 59/200\n",
      "15/15 - 0s - loss: 0.2946 - accuracy: 0.8966 - 10ms/epoch - 644us/step\n",
      "Epoch 60/200\n",
      "15/15 - 0s - loss: 0.2975 - accuracy: 0.8828 - 10ms/epoch - 655us/step\n",
      "Epoch 61/200\n",
      "15/15 - 0s - loss: 0.2937 - accuracy: 0.8828 - 10ms/epoch - 659us/step\n",
      "Epoch 62/200\n",
      "15/15 - 0s - loss: 0.2833 - accuracy: 0.9034 - 10ms/epoch - 646us/step\n",
      "Epoch 63/200\n",
      "15/15 - 0s - loss: 0.2833 - accuracy: 0.8828 - 10ms/epoch - 658us/step\n",
      "Epoch 64/200\n",
      "15/15 - 0s - loss: 0.3002 - accuracy: 0.8897 - 10ms/epoch - 651us/step\n",
      "Epoch 65/200\n",
      "15/15 - 0s - loss: 0.2897 - accuracy: 0.8897 - 10ms/epoch - 653us/step\n",
      "Epoch 66/200\n",
      "15/15 - 0s - loss: 0.2717 - accuracy: 0.9034 - 10ms/epoch - 671us/step\n",
      "Epoch 67/200\n",
      "15/15 - 0s - loss: 0.2700 - accuracy: 0.9034 - 10ms/epoch - 657us/step\n",
      "Epoch 68/200\n",
      "15/15 - 0s - loss: 0.2630 - accuracy: 0.9103 - 10ms/epoch - 651us/step\n",
      "Epoch 69/200\n",
      "15/15 - 0s - loss: 0.2586 - accuracy: 0.9034 - 10ms/epoch - 664us/step\n",
      "Epoch 70/200\n",
      "15/15 - 0s - loss: 0.2532 - accuracy: 0.9172 - 10ms/epoch - 648us/step\n",
      "Epoch 71/200\n",
      "15/15 - 0s - loss: 0.2447 - accuracy: 0.9172 - 10ms/epoch - 650us/step\n",
      "Epoch 72/200\n",
      "15/15 - 0s - loss: 0.2482 - accuracy: 0.9034 - 10ms/epoch - 653us/step\n",
      "Epoch 73/200\n",
      "15/15 - 0s - loss: 0.2568 - accuracy: 0.9103 - 10ms/epoch - 643us/step\n",
      "Epoch 74/200\n",
      "15/15 - 0s - loss: 0.2429 - accuracy: 0.9241 - 10ms/epoch - 650us/step\n",
      "Epoch 75/200\n",
      "15/15 - 0s - loss: 0.2415 - accuracy: 0.9310 - 10ms/epoch - 652us/step\n",
      "Epoch 76/200\n",
      "15/15 - 0s - loss: 0.2299 - accuracy: 0.9241 - 10ms/epoch - 654us/step\n",
      "Epoch 77/200\n",
      "15/15 - 0s - loss: 0.2179 - accuracy: 0.9241 - 10ms/epoch - 663us/step\n",
      "Epoch 78/200\n",
      "15/15 - 0s - loss: 0.2168 - accuracy: 0.9241 - 10ms/epoch - 652us/step\n",
      "Epoch 79/200\n",
      "15/15 - 0s - loss: 0.2130 - accuracy: 0.9310 - 10ms/epoch - 656us/step\n",
      "Epoch 80/200\n",
      "15/15 - 0s - loss: 0.2109 - accuracy: 0.9241 - 10ms/epoch - 659us/step\n",
      "Epoch 81/200\n",
      "15/15 - 0s - loss: 0.2045 - accuracy: 0.9310 - 10ms/epoch - 656us/step\n",
      "Epoch 82/200\n",
      "15/15 - 0s - loss: 0.2035 - accuracy: 0.9448 - 10ms/epoch - 664us/step\n",
      "Epoch 83/200\n",
      "15/15 - 0s - loss: 0.2025 - accuracy: 0.9379 - 10ms/epoch - 661us/step\n",
      "Epoch 84/200\n",
      "15/15 - 0s - loss: 0.1982 - accuracy: 0.9379 - 10ms/epoch - 647us/step\n",
      "Epoch 85/200\n",
      "15/15 - 0s - loss: 0.1901 - accuracy: 0.9310 - 10ms/epoch - 671us/step\n",
      "Epoch 86/200\n",
      "15/15 - 0s - loss: 0.1931 - accuracy: 0.9310 - 10ms/epoch - 668us/step\n",
      "Epoch 87/200\n",
      "15/15 - 0s - loss: 0.1841 - accuracy: 0.9586 - 10ms/epoch - 646us/step\n",
      "Epoch 88/200\n",
      "15/15 - 0s - loss: 0.1853 - accuracy: 0.9310 - 10ms/epoch - 656us/step\n",
      "Epoch 89/200\n",
      "15/15 - 0s - loss: 0.1868 - accuracy: 0.9448 - 10ms/epoch - 655us/step\n",
      "Epoch 90/200\n",
      "15/15 - 0s - loss: 0.1753 - accuracy: 0.9586 - 10ms/epoch - 646us/step\n",
      "Epoch 91/200\n",
      "15/15 - 0s - loss: 0.1729 - accuracy: 0.9448 - 10ms/epoch - 659us/step\n",
      "Epoch 92/200\n",
      "15/15 - 0s - loss: 0.1663 - accuracy: 0.9655 - 10ms/epoch - 654us/step\n",
      "Epoch 93/200\n",
      "15/15 - 0s - loss: 0.1651 - accuracy: 0.9379 - 33ms/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "15/15 - 0s - loss: 0.1635 - accuracy: 0.9724 - 10ms/epoch - 690us/step\n",
      "Epoch 95/200\n",
      "15/15 - 0s - loss: 0.1683 - accuracy: 0.9517 - 10ms/epoch - 683us/step\n",
      "Epoch 96/200\n",
      "15/15 - 0s - loss: 0.1610 - accuracy: 0.9448 - 10ms/epoch - 653us/step\n",
      "Epoch 97/200\n",
      "15/15 - 0s - loss: 0.1702 - accuracy: 0.9448 - 10ms/epoch - 657us/step\n",
      "Epoch 98/200\n",
      "15/15 - 0s - loss: 0.1544 - accuracy: 0.9517 - 10ms/epoch - 654us/step\n",
      "Epoch 99/200\n",
      "15/15 - 0s - loss: 0.1450 - accuracy: 0.9517 - 10ms/epoch - 677us/step\n",
      "Epoch 100/200\n",
      "15/15 - 0s - loss: 0.1550 - accuracy: 0.9586 - 10ms/epoch - 669us/step\n",
      "Epoch 101/200\n",
      "15/15 - 0s - loss: 0.1454 - accuracy: 0.9517 - 10ms/epoch - 660us/step\n",
      "Epoch 102/200\n",
      "15/15 - 0s - loss: 0.1434 - accuracy: 0.9724 - 10ms/epoch - 670us/step\n",
      "Epoch 103/200\n",
      "15/15 - 0s - loss: 0.1501 - accuracy: 0.9586 - 10ms/epoch - 664us/step\n",
      "Epoch 104/200\n",
      "15/15 - 0s - loss: 0.1333 - accuracy: 0.9655 - 10ms/epoch - 660us/step\n",
      "Epoch 105/200\n",
      "15/15 - 0s - loss: 0.1285 - accuracy: 0.9655 - 10ms/epoch - 638us/step\n",
      "Epoch 106/200\n",
      "15/15 - 0s - loss: 0.1297 - accuracy: 0.9586 - 10ms/epoch - 658us/step\n",
      "Epoch 107/200\n",
      "15/15 - 0s - loss: 0.1295 - accuracy: 0.9862 - 10ms/epoch - 646us/step\n",
      "Epoch 108/200\n",
      "15/15 - 0s - loss: 0.1426 - accuracy: 0.9379 - 10ms/epoch - 653us/step\n",
      "Epoch 109/200\n",
      "15/15 - 0s - loss: 0.1216 - accuracy: 0.9862 - 10ms/epoch - 656us/step\n",
      "Epoch 110/200\n",
      "15/15 - 0s - loss: 0.1210 - accuracy: 0.9724 - 10ms/epoch - 651us/step\n",
      "Epoch 111/200\n",
      "15/15 - 0s - loss: 0.1147 - accuracy: 0.9862 - 10ms/epoch - 669us/step\n",
      "Epoch 112/200\n",
      "15/15 - 0s - loss: 0.1191 - accuracy: 0.9586 - 10ms/epoch - 656us/step\n",
      "Epoch 113/200\n",
      "15/15 - 0s - loss: 0.1094 - accuracy: 0.9862 - 10ms/epoch - 656us/step\n",
      "Epoch 114/200\n",
      "15/15 - 0s - loss: 0.1086 - accuracy: 0.9793 - 10ms/epoch - 657us/step\n",
      "Epoch 115/200\n",
      "15/15 - 0s - loss: 0.1054 - accuracy: 0.9931 - 10ms/epoch - 664us/step\n",
      "Epoch 116/200\n",
      "15/15 - 0s - loss: 0.1072 - accuracy: 0.9724 - 10ms/epoch - 651us/step\n",
      "Epoch 117/200\n",
      "15/15 - 0s - loss: 0.1117 - accuracy: 0.9586 - 10ms/epoch - 636us/step\n",
      "Epoch 118/200\n",
      "15/15 - 0s - loss: 0.1033 - accuracy: 0.9931 - 10ms/epoch - 667us/step\n",
      "Epoch 119/200\n",
      "15/15 - 0s - loss: 0.0986 - accuracy: 0.9931 - 10ms/epoch - 659us/step\n",
      "Epoch 120/200\n",
      "15/15 - 0s - loss: 0.0944 - accuracy: 0.9931 - 10ms/epoch - 657us/step\n",
      "Epoch 121/200\n",
      "15/15 - 0s - loss: 0.0927 - accuracy: 0.9793 - 10ms/epoch - 656us/step\n",
      "Epoch 122/200\n",
      "15/15 - 0s - loss: 0.0910 - accuracy: 0.9862 - 10ms/epoch - 652us/step\n",
      "Epoch 123/200\n",
      "15/15 - 0s - loss: 0.0928 - accuracy: 0.9862 - 10ms/epoch - 643us/step\n",
      "Epoch 124/200\n",
      "15/15 - 0s - loss: 0.0966 - accuracy: 0.9862 - 10ms/epoch - 659us/step\n",
      "Epoch 125/200\n",
      "15/15 - 0s - loss: 0.0951 - accuracy: 0.9793 - 10ms/epoch - 652us/step\n",
      "Epoch 126/200\n",
      "15/15 - 0s - loss: 0.0810 - accuracy: 0.9931 - 10ms/epoch - 651us/step\n",
      "Epoch 127/200\n",
      "15/15 - 0s - loss: 0.0856 - accuracy: 0.9931 - 10ms/epoch - 662us/step\n",
      "Epoch 128/200\n",
      "15/15 - 0s - loss: 0.0794 - accuracy: 1.0000 - 10ms/epoch - 652us/step\n",
      "Epoch 129/200\n",
      "15/15 - 0s - loss: 0.0769 - accuracy: 0.9931 - 10ms/epoch - 660us/step\n",
      "Epoch 130/200\n",
      "15/15 - 0s - loss: 0.0768 - accuracy: 0.9931 - 10ms/epoch - 653us/step\n",
      "Epoch 131/200\n",
      "15/15 - 0s - loss: 0.0770 - accuracy: 0.9931 - 10ms/epoch - 653us/step\n",
      "Epoch 132/200\n",
      "15/15 - 0s - loss: 0.0725 - accuracy: 0.9931 - 10ms/epoch - 650us/step\n",
      "Epoch 133/200\n",
      "15/15 - 0s - loss: 0.0730 - accuracy: 0.9862 - 10ms/epoch - 648us/step\n",
      "Epoch 134/200\n",
      "15/15 - 0s - loss: 0.0772 - accuracy: 0.9931 - 10ms/epoch - 659us/step\n",
      "Epoch 135/200\n",
      "15/15 - 0s - loss: 0.0726 - accuracy: 0.9931 - 10ms/epoch - 656us/step\n",
      "Epoch 136/200\n",
      "15/15 - 0s - loss: 0.0702 - accuracy: 0.9931 - 10ms/epoch - 663us/step\n",
      "Epoch 137/200\n",
      "15/15 - 0s - loss: 0.0708 - accuracy: 0.9931 - 10ms/epoch - 654us/step\n",
      "Epoch 138/200\n",
      "15/15 - 0s - loss: 0.0754 - accuracy: 0.9931 - 10ms/epoch - 648us/step\n",
      "Epoch 139/200\n",
      "15/15 - 0s - loss: 0.0659 - accuracy: 0.9931 - 10ms/epoch - 664us/step\n",
      "Epoch 140/200\n",
      "15/15 - 0s - loss: 0.0681 - accuracy: 0.9931 - 10ms/epoch - 659us/step\n",
      "Epoch 141/200\n",
      "15/15 - 0s - loss: 0.0609 - accuracy: 1.0000 - 10ms/epoch - 664us/step\n",
      "Epoch 142/200\n",
      "15/15 - 0s - loss: 0.0602 - accuracy: 0.9931 - 10ms/epoch - 656us/step\n",
      "Epoch 143/200\n",
      "15/15 - 0s - loss: 0.0569 - accuracy: 1.0000 - 10ms/epoch - 652us/step\n",
      "Epoch 144/200\n",
      "15/15 - 0s - loss: 0.0568 - accuracy: 1.0000 - 10ms/epoch - 651us/step\n",
      "Epoch 145/200\n",
      "15/15 - 0s - loss: 0.0594 - accuracy: 0.9931 - 10ms/epoch - 671us/step\n",
      "Epoch 146/200\n",
      "15/15 - 0s - loss: 0.0542 - accuracy: 0.9931 - 10ms/epoch - 659us/step\n",
      "Epoch 147/200\n",
      "15/15 - 0s - loss: 0.0543 - accuracy: 1.0000 - 10ms/epoch - 660us/step\n",
      "Epoch 148/200\n",
      "15/15 - 0s - loss: 0.0544 - accuracy: 0.9931 - 10ms/epoch - 649us/step\n",
      "Epoch 149/200\n",
      "15/15 - 0s - loss: 0.0550 - accuracy: 0.9931 - 10ms/epoch - 641us/step\n",
      "Epoch 150/200\n",
      "15/15 - 0s - loss: 0.0532 - accuracy: 1.0000 - 10ms/epoch - 655us/step\n",
      "Epoch 151/200\n",
      "15/15 - 0s - loss: 0.0539 - accuracy: 0.9931 - 10ms/epoch - 650us/step\n",
      "Epoch 152/200\n",
      "15/15 - 0s - loss: 0.0528 - accuracy: 1.0000 - 10ms/epoch - 652us/step\n",
      "Epoch 153/200\n",
      "15/15 - 0s - loss: 0.0472 - accuracy: 0.9931 - 10ms/epoch - 652us/step\n",
      "Epoch 154/200\n",
      "15/15 - 0s - loss: 0.0447 - accuracy: 1.0000 - 10ms/epoch - 650us/step\n",
      "Epoch 155/200\n",
      "15/15 - 0s - loss: 0.0471 - accuracy: 1.0000 - 10ms/epoch - 649us/step\n",
      "Epoch 156/200\n",
      "15/15 - 0s - loss: 0.0455 - accuracy: 0.9931 - 10ms/epoch - 662us/step\n",
      "Epoch 157/200\n",
      "15/15 - 0s - loss: 0.0430 - accuracy: 1.0000 - 10ms/epoch - 659us/step\n",
      "Epoch 158/200\n",
      "15/15 - 0s - loss: 0.0461 - accuracy: 1.0000 - 10ms/epoch - 660us/step\n",
      "Epoch 159/200\n",
      "15/15 - 0s - loss: 0.0423 - accuracy: 1.0000 - 10ms/epoch - 658us/step\n",
      "Epoch 160/200\n",
      "15/15 - 0s - loss: 0.0409 - accuracy: 1.0000 - 10ms/epoch - 653us/step\n",
      "Epoch 161/200\n",
      "15/15 - 0s - loss: 0.0414 - accuracy: 0.9931 - 10ms/epoch - 652us/step\n",
      "Epoch 162/200\n",
      "15/15 - 0s - loss: 0.0402 - accuracy: 0.9931 - 10ms/epoch - 650us/step\n",
      "Epoch 163/200\n",
      "15/15 - 0s - loss: 0.0376 - accuracy: 1.0000 - 10ms/epoch - 642us/step\n",
      "Epoch 164/200\n",
      "15/15 - 0s - loss: 0.0385 - accuracy: 1.0000 - 10ms/epoch - 659us/step\n",
      "Epoch 165/200\n",
      "15/15 - 0s - loss: 0.0378 - accuracy: 1.0000 - 10ms/epoch - 639us/step\n",
      "Epoch 166/200\n",
      "15/15 - 0s - loss: 0.0382 - accuracy: 1.0000 - 10ms/epoch - 650us/step\n",
      "Epoch 167/200\n",
      "15/15 - 0s - loss: 0.0378 - accuracy: 0.9931 - 10ms/epoch - 662us/step\n",
      "Epoch 168/200\n",
      "15/15 - 0s - loss: 0.0348 - accuracy: 1.0000 - 10ms/epoch - 652us/step\n",
      "Epoch 169/200\n",
      "15/15 - 0s - loss: 0.0346 - accuracy: 1.0000 - 10ms/epoch - 646us/step\n",
      "Epoch 170/200\n",
      "15/15 - 0s - loss: 0.0342 - accuracy: 1.0000 - 10ms/epoch - 666us/step\n",
      "Epoch 171/200\n",
      "15/15 - 0s - loss: 0.0353 - accuracy: 1.0000 - 10ms/epoch - 653us/step\n",
      "Epoch 172/200\n",
      "15/15 - 0s - loss: 0.0328 - accuracy: 1.0000 - 10ms/epoch - 649us/step\n",
      "Epoch 173/200\n",
      "15/15 - 0s - loss: 0.0315 - accuracy: 1.0000 - 10ms/epoch - 662us/step\n",
      "Epoch 174/200\n",
      "15/15 - 0s - loss: 0.0304 - accuracy: 1.0000 - 10ms/epoch - 644us/step\n",
      "Epoch 175/200\n",
      "15/15 - 0s - loss: 0.0308 - accuracy: 1.0000 - 10ms/epoch - 661us/step\n",
      "Epoch 176/200\n",
      "15/15 - 0s - loss: 0.0309 - accuracy: 1.0000 - 10ms/epoch - 645us/step\n",
      "Epoch 177/200\n",
      "15/15 - 0s - loss: 0.0301 - accuracy: 1.0000 - 10ms/epoch - 645us/step\n",
      "Epoch 178/200\n",
      "15/15 - 0s - loss: 0.0285 - accuracy: 1.0000 - 10ms/epoch - 657us/step\n",
      "Epoch 179/200\n",
      "15/15 - 0s - loss: 0.0299 - accuracy: 1.0000 - 10ms/epoch - 666us/step\n",
      "Epoch 180/200\n",
      "15/15 - 0s - loss: 0.0279 - accuracy: 1.0000 - 10ms/epoch - 649us/step\n",
      "Epoch 181/200\n",
      "15/15 - 0s - loss: 0.0286 - accuracy: 1.0000 - 10ms/epoch - 657us/step\n",
      "Epoch 182/200\n",
      "15/15 - 0s - loss: 0.0274 - accuracy: 1.0000 - 10ms/epoch - 651us/step\n",
      "Epoch 183/200\n",
      "15/15 - 0s - loss: 0.0275 - accuracy: 1.0000 - 10ms/epoch - 644us/step\n",
      "Epoch 184/200\n",
      "15/15 - 0s - loss: 0.0264 - accuracy: 1.0000 - 10ms/epoch - 661us/step\n",
      "Epoch 185/200\n",
      "15/15 - 0s - loss: 0.0270 - accuracy: 1.0000 - 10ms/epoch - 650us/step\n",
      "Epoch 186/200\n",
      "15/15 - 0s - loss: 0.0258 - accuracy: 1.0000 - 10ms/epoch - 653us/step\n",
      "Epoch 187/200\n",
      "15/15 - 0s - loss: 0.0249 - accuracy: 1.0000 - 10ms/epoch - 659us/step\n",
      "Epoch 188/200\n",
      "15/15 - 0s - loss: 0.0243 - accuracy: 1.0000 - 10ms/epoch - 654us/step\n",
      "Epoch 189/200\n",
      "15/15 - 0s - loss: 0.0239 - accuracy: 1.0000 - 10ms/epoch - 652us/step\n",
      "Epoch 190/200\n",
      "15/15 - 0s - loss: 0.0226 - accuracy: 1.0000 - 10ms/epoch - 654us/step\n",
      "Epoch 191/200\n",
      "15/15 - 0s - loss: 0.0240 - accuracy: 1.0000 - 10ms/epoch - 647us/step\n",
      "Epoch 192/200\n",
      "15/15 - 0s - loss: 0.0247 - accuracy: 1.0000 - 10ms/epoch - 658us/step\n",
      "Epoch 193/200\n",
      "15/15 - 0s - loss: 0.0223 - accuracy: 1.0000 - 10ms/epoch - 657us/step\n",
      "Epoch 194/200\n",
      "15/15 - 0s - loss: 0.0212 - accuracy: 1.0000 - 10ms/epoch - 650us/step\n",
      "Epoch 195/200\n",
      "15/15 - 0s - loss: 0.0215 - accuracy: 1.0000 - 10ms/epoch - 660us/step\n",
      "Epoch 196/200\n",
      "15/15 - 0s - loss: 0.0206 - accuracy: 1.0000 - 10ms/epoch - 647us/step\n",
      "Epoch 197/200\n",
      "15/15 - 0s - loss: 0.0199 - accuracy: 1.0000 - 10ms/epoch - 641us/step\n",
      "Epoch 198/200\n",
      "15/15 - 0s - loss: 0.0199 - accuracy: 1.0000 - 10ms/epoch - 676us/step\n",
      "Epoch 199/200\n",
      "15/15 - 0s - loss: 0.0198 - accuracy: 1.0000 - 10ms/epoch - 660us/step\n",
      "Epoch 200/200\n",
      "15/15 - 0s - loss: 0.0200 - accuracy: 1.0000 - 10ms/epoch - 661us/step\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8571\n",
      "테스트 손실 : 45.06 %\n",
      "테스트 정확도 : 85.71 %\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(60,)))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=10, verbose=2)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"테스트 손실 : %.2f %%\" % (score[0]*100))\n",
    "print(\"테스트 정확도 : %.2f %%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용: 100.00%\n",
      "시험용: 85.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장하기 : model.save()\n",
    "model.save(\"./my_model_13.hdf5\") \n",
    "\n",
    "# 모델 불러오기 \n",
    "from keras.models import load_model\n",
    "\n",
    "del model # 메모리에 저장된 모델 삭제 \n",
    "\n",
    "# 모델 불러오기 \n",
    "model = load_model(\"./my_model_13.hdf5\")\n",
    "\n",
    "# 모델을 테스트셋에 적용하여 정확도 구하기 \n",
    "print(\"학습용: %.2f%%\" % (100*model.evaluate(x_train, y_train, verbose=0)[1]))\n",
    "print(\"시험용: %.2f%%\" % (100*model.evaluate(x_test, y_test, verbose=0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross-Validation  (CV)\n",
    "\n",
    "<b>데이터셋을 여러 개로 나누어 하나씩 테스트셋으로 사용하고 나머지를 합하여 학습셋으로 사용</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 함수 사용 \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 5 # 몇 개로 나눌 것인지 정함 \n",
    "kfold = KFold(n_splits=k, shuffle=True) # k개 만큼 분리, 데이터 셔플 ㅇㅇ \n",
    "acc_score = [] # 정확도 저장 변수 \n",
    "\n",
    "# k개의 학습셋, 테스트셋으로 분리 \n",
    "for train_idx, test_idx in kfold.split(x):\n",
    "    x_train, x_test = x.iloc[train_idx, :], x.iloc[test_idx, : ] \n",
    "    y_train, y_test = y.iloc[train_idx] , y.iloc[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.0396 - accuracy: 1.0000 - 10ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# 정확도 구하기 \n",
    "accuarcy = model.evaluate(x_test, y_test, verbose=2)[1]\n",
    "acc_score.append(accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  [1.0, 0.8809523582458496, 0.8333333134651184, 0.761904776096344, 0.8048780560493469, 0.8048780560493469]\n",
      "모델의 평균 정확도: 1.0171893119812012\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습까지 작성 \n",
    "for train_index, test_index in kfold.split(x):\n",
    "  x_train = x.iloc[train_index, 0:60]\n",
    "  x_test = x.iloc[test_index, :]\n",
    "\n",
    "  y_train = y.iloc[train_index]\n",
    "  y_test = y.iloc[test_index]\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Input(shape=(60, )))  # 입력층 추가!\n",
    "  model.add(Dense(24, activation=\"relu\"))  # 밀집층 추가! (은닉층)\n",
    "  model.add(Dense(10, activation=\"relu\"))  # 밀집층 추가! (은닉층)\n",
    "  model.add(Dense(1, activation=\"sigmoid\"))  # 밀집층 추가! -> 출력층!\n",
    "  \n",
    "  model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "  \n",
    "  model.fit(x_train, y_train, epochs=200, batch_size=10, verbose=0)\n",
    "\n",
    "  acc_score.append(model.evaluate(x_test, y_test, verbose=0)[1])\n",
    "  \n",
    "\n",
    "# 정확도 구하기 \n",
    "avg_acc = sum(acc_score)/k\n",
    "\n",
    "# 값 출력 \n",
    "print(\"정확도 : \", acc_score)\n",
    "\n",
    "# 평균 출력 \n",
    "print(\"모델의 평균 정확도:\", sum(acc_score) / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
